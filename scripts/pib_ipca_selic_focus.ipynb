{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e539403",
   "metadata": {},
   "source": [
    "### Dados Macroeconômicos Seção 4 (01/1999 a 12/2024)\n",
    "\n",
    "* PIB (Trimestral) - IBGE - sidrapy - Tabela 1621\n",
    "* IPCA (Mensal)\t- BCB - python-bcb - SGS 433\n",
    "* IPCA (12 meses) - BCB - python-bcb - SGS 13522\n",
    "* Selic Meta - BCB - python-bcb - SGS 432\n",
    "* Expectativas - BCB - python-bcb - Endpoint Expectativas - Filtrar por Indicador='IPCA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c26dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-bcb pandas matplotlib seaborn sidrapy\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bcb import sgs\n",
    "from bcb import Expectativas\n",
    "import sidrapy\n",
    "import datetime\n",
    "\n",
    "# Configurações de Estilo\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "# Parâmetros Globais\n",
    "DATA_INICIAL = '1999-01-01'\n",
    "DATA_FINAL = '2024-12-31'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ef5118",
   "metadata": {},
   "source": [
    "# 2. Coleta de Dados via SGS (Sistema Gerenciador de Séries)\n",
    "Coleta das séries de IPCA e Selic diretamente do Banco Central utilizando o módulo `sgs`.\n",
    "- **433**: IPCA Mensal (%)\n",
    "- **13522**: IPCA Acumulado 12 meses (%)\n",
    "- **432**: Meta Selic (% a.a.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e9626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando coleta de dados do SGS...\n",
      "Coletando chunk: 1999-01-01 até 2004-01-01\n",
      "Erro na coleta do chunk 1999-01-01: Download error: code = 433\n",
      "Coletando chunk: 2004-01-02 até 2009-01-02\n",
      "Erro na coleta do chunk 2004-01-02: Download error: code = 433\n",
      "Coletando chunk: 2009-01-03 até 2014-01-03\n",
      "Erro na coleta do chunk 2009-01-03: Download error: code = 433\n",
      "Coletando chunk: 2014-01-04 até 2019-01-04\n",
      "Erro na coleta do chunk 2014-01-04: Download error: code = 433\n",
      "Coletando chunk: 2019-01-05 até 2024-01-05\n",
      "Erro na coleta do chunk 2019-01-05: Download error: code = 433\n",
      "Coletando chunk: 2024-01-06 até 2024-12-31\n",
      "Erro na coleta do chunk 2024-01-06: Download error: code = 433\n",
      "SGS indisponível (ex: HTTP 403 'Acesso Negado'). Tentando fallback local em dados/rafaela...\n",
      "Dados locais carregados: 9492 registros.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(            IPCA_Mensal  IPCA_12m  Selic_Meta\n",
       " 1999-01-01         0.68       1.8        29.0\n",
       " 1999-01-02          NaN       NaN        29.0\n",
       " 1999-01-03          NaN       NaN        29.0\n",
       " 1999-01-04          NaN       NaN        29.0\n",
       " 1999-01-05          NaN       NaN        29.0,\n",
       "             IPCA_Mensal  IPCA_12m  Selic_Meta\n",
       " 2024-12-27          NaN       NaN       12.25\n",
       " 2024-12-28          NaN       NaN       12.25\n",
       " 2024-12-29          NaN       NaN       12.25\n",
       " 2024-12-30          NaN       NaN       12.25\n",
       " 2024-12-31          NaN       NaN       12.25)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def _encontrar_raiz_projeto() -> Path:\n",
    "    cwd = Path.cwd().resolve()\n",
    "    for p in (cwd, *cwd.parents):\n",
    "        if (p / 'dados').exists():\n",
    "            return p\n",
    "    return cwd\n",
    "\n",
    "\n",
    "def _to_float_misto_ptbr(x):\n",
    "    import numpy as np\n",
    "\n",
    "    if x is None:\n",
    "        return np.nan\n",
    "    s = str(x).strip()\n",
    "    if not s or s.lower() == 'nan':\n",
    "        return np.nan\n",
    "\n",
    "    # Trata números em formato pt-BR (ex: 15,00) e mistos (ex: 1.234,56)\n",
    "    if ',' in s and '.' in s:\n",
    "        s = s.replace('.', '').replace(',', '.')\n",
    "    elif ',' in s:\n",
    "        s = s.replace(',', '.')\n",
    "\n",
    "    try:\n",
    "        return float(s)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def _coleta_sgs_fallback_local(data_inicial: str, data_final: str, pasta_dados_rel: str = 'dados/rafaela') -> pd.DataFrame:\n",
    "    \"\"\"Fallback quando o SGS (api.bcb.gov.br) está bloqueado (ex: HTTP 403).\n",
    "\n",
    "    Usa arquivos locais existentes no repositório:\n",
    "    - IPCA15_mensal.csv (proxy para inflação mensal/12m)\n",
    "    - Taxa_selic_aa.csv (Meta Selic por vigência -> série diária)\n",
    "    \"\"\"\n",
    "    raiz = _encontrar_raiz_projeto()\n",
    "    pasta = (raiz / pasta_dados_rel).resolve()\n",
    "\n",
    "    ipca_path = pasta / 'IPCA15_mensal.csv'\n",
    "    selic_path = pasta / 'Taxa_selic_aa.csv'\n",
    "\n",
    "    dfs = []\n",
    "    data_inicial_dt = pd.to_datetime(data_inicial)\n",
    "    data_final_dt = pd.to_datetime(data_final)\n",
    "\n",
    "    # IPCA (fallback via IPCA-15)\n",
    "    if ipca_path.exists():\n",
    "        df_ipca = pd.read_csv(ipca_path, sep=';')\n",
    "        mapa_mes = {\n",
    "            'JAN': 1, 'FEV': 2, 'MAR': 3, 'ABR': 4, 'MAI': 5, 'JUN': 6,\n",
    "            'JUL': 7, 'AGO': 8, 'SET': 9, 'OUT': 10, 'NOV': 11, 'DEZ': 12,\n",
    "        }\n",
    "        df_ipca['MesNum'] = df_ipca['MÊS'].astype(str).str.strip().str.upper().map(mapa_mes)\n",
    "        df_ipca = df_ipca.dropna(subset=['MesNum'])\n",
    "        df_ipca['Data'] = pd.to_datetime(\n",
    "            df_ipca['ANO'].astype(int).astype(str)\n",
    "            + '-'\n",
    "            + df_ipca['MesNum'].astype(int).astype(str)\n",
    "            + '-01'\n",
    "        )\n",
    "        df_ipca = df_ipca.set_index('Data').sort_index()\n",
    "        df_ipca = df_ipca.rename(columns={\n",
    "            'VAR_PERC_MES': 'IPCA_Mensal',\n",
    "            'VAR_PERC_12_MESES': 'IPCA_12m',\n",
    "        })\n",
    "        df_ipca['IPCA_Mensal'] = pd.to_numeric(df_ipca['IPCA_Mensal'], errors='coerce')\n",
    "        df_ipca['IPCA_12m'] = pd.to_numeric(df_ipca['IPCA_12m'], errors='coerce')\n",
    "        df_ipca = df_ipca[['IPCA_Mensal', 'IPCA_12m']]\n",
    "        dfs.append(df_ipca)\n",
    "    else:\n",
    "        print(f\"Fallback local: arquivo não encontrado: {ipca_path}\")\n",
    "\n",
    "    # Selic Meta (fallback via arquivo de vigências)\n",
    "    if selic_path.exists():\n",
    "        df_selic_raw = pd.read_csv(selic_path, sep=';', dtype=str)\n",
    "        df_selic_raw['META_SELIC_aa'] = df_selic_raw['META_SELIC_aa'].apply(_to_float_misto_ptbr)\n",
    "\n",
    "        vig = df_selic_raw['VIGENCIA'].fillna('')\n",
    "        partes = vig.str.split('-', n=1, expand=True)\n",
    "        inicio_str = partes[0].astype(str).str.strip()\n",
    "        fim_str = partes[1].astype(str).str.strip() if partes.shape[1] > 1 else ''\n",
    "\n",
    "        df_selic_raw['Inicio'] = pd.to_datetime(inicio_str, dayfirst=True, errors='coerce')\n",
    "        df_selic_raw['Fim'] = pd.to_datetime(fim_str, dayfirst=True, errors='coerce')\n",
    "\n",
    "        series_parts = []\n",
    "        for row in df_selic_raw.itertuples(index=False):\n",
    "            start = getattr(row, 'Inicio')\n",
    "            end = getattr(row, 'Fim')\n",
    "            val = getattr(row, 'META_SELIC_aa')\n",
    "\n",
    "            if pd.isna(start) or pd.isna(val):\n",
    "                continue\n",
    "            if pd.isna(end):\n",
    "                end = data_final_dt\n",
    "            if end < start:\n",
    "                continue\n",
    "\n",
    "            rng = pd.date_range(start, end, freq='D')\n",
    "            series_parts.append(pd.Series(val, index=rng))\n",
    "\n",
    "        if series_parts:\n",
    "            selic = pd.concat(series_parts).sort_index()\n",
    "            selic = selic[~selic.index.duplicated(keep='last')]\n",
    "            df_selic = selic.to_frame('Selic_Meta')\n",
    "            dfs.append(df_selic)\n",
    "        else:\n",
    "            print(\"Fallback local: não foi possível construir a série diária da Selic a partir das vigências.\")\n",
    "    else:\n",
    "        print(f\"Fallback local: arquivo não encontrado: {selic_path}\")\n",
    "\n",
    "    if not dfs:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.concat(dfs, axis=1).sort_index()\n",
    "    df = df[(df.index >= data_inicial_dt) & (df.index <= data_final_dt)]\n",
    "    return df\n",
    "\n",
    "\n",
    "def coleta_dados_sgs():\n",
    "    print(\"Iniciando coleta de dados do SGS...\")\n",
    "    # O formato correto para sgs.get é {'Nome_da_Coluna': Codigo_SGS}\n",
    "    codigos = {\n",
    "        'IPCA_Mensal': 433,\n",
    "        'IPCA_12m': 13522,\n",
    "        'Selic_Meta': 432\n",
    "    }\n",
    "\n",
    "    dfs = []\n",
    "    start_date = pd.to_datetime(DATA_INICIAL)\n",
    "    end_date = pd.to_datetime(DATA_FINAL)\n",
    "\n",
    "    # Loop em janelas para reduzir risco de timeouts\n",
    "    while start_date <= end_date:\n",
    "        window_end = start_date + pd.DateOffset(years=5)\n",
    "        if window_end > end_date:\n",
    "            window_end = end_date\n",
    "\n",
    "        print(f\"Coletando chunk: {start_date.date()} até {window_end.date()}\")\n",
    "\n",
    "        try:\n",
    "            # Força datetime/date simples (melhor compatibilidade)\n",
    "            df_chunk = sgs.get(codigos, start=start_date.date(), end=window_end.date())\n",
    "            if not df_chunk.empty:\n",
    "                dfs.append(df_chunk)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na coleta do chunk {start_date.date()}: {e}\")\n",
    "\n",
    "        start_date = window_end + pd.Timedelta(days=1)\n",
    "\n",
    "    if dfs:\n",
    "        df = pd.concat(dfs)\n",
    "        df = df[~df.index.duplicated(keep='first')]\n",
    "        print(f\"Dados SGS coletados: {df.shape[0]} registros.\")\n",
    "        return df\n",
    "\n",
    "    print(\"SGS indisponível (ex: HTTP 403 'Acesso Negado'). Tentando fallback local em dados/rafaela...\")\n",
    "    df_local = _coleta_sgs_fallback_local(DATA_INICIAL, DATA_FINAL)\n",
    "    if df_local.empty:\n",
    "        print(\"Fallback local também falhou: retornando DataFrame vazio.\")\n",
    "    else:\n",
    "        print(f\"Dados locais carregados: {df_local.shape[0]} registros.\")\n",
    "    return df_local\n",
    "\n",
    "\n",
    "df_sgs = coleta_dados_sgs()\n",
    "df_sgs.head(), df_sgs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ec4574",
   "metadata": {},
   "source": [
    "# 3. Coleta de Dados do PIB (IBGE)\n",
    "Coleta da série do PIB trimestral utilizando a biblioteca `sidrapy`.\n",
    "- **Tabela 1621**: Série encadeada do índice de volume trimestral com ajuste sazonal.\n",
    "- **Variável 584**: Índice de volume trimestral com ajuste sazonal.\n",
    "- **Setor**: PIB a preços de mercado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coleta_pib():\n",
    "    print(\"Iniciando coleta de dados do PIB (IBGE)...\")\n",
    "    # Tabela 1621: Série encadeada do índice de volume trimestral com ajuste sazonal\n",
    "    # Variável 584: Série encadeada do índice de volume trimestral com ajuste sazonal (Base: média de 1995 = 100)\n",
    "    # Classificação 11255: Setores de atividade -> 90707: PIB a preços de mercado\n",
    "    \n",
    "    try:\n",
    "        pib = sidrapy.get_table(\n",
    "            table_code=\"1621\",\n",
    "            territorial_level=\"1\",\n",
    "            ibge_territorial_code=\"all\",\n",
    "            variable=\"584\",\n",
    "            classification=\"11255/90707\",\n",
    "            period=\"all\"\n",
    "        )\n",
    "        \n",
    "        # Limpeza e tratamento\n",
    "        if pib.empty:\n",
    "            print(\"Retorno vazio do sidrapy.\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        pib = pib.iloc[1:] # Remove a linha de cabeçalho/descrição\n",
    "        pib = pib[['V', 'D2C']] # V: Valor, D2C: Trimestre (ex: 199601)\n",
    "        pib.columns = ['PIB_Indice', 'Trimestre']\n",
    "        \n",
    "        # Converter valor para numérico\n",
    "        pib['PIB_Indice'] = pd.to_numeric(pib['PIB_Indice'])\n",
    "        \n",
    "        # Converter Trimestre para Data (Primeiro dia do trimestre)\n",
    "        # Formato IBGE: YYYY0Q (ex: 199901 -> 1º tri 1999)\n",
    "        # 01 -> Mês 01, 02 -> Mês 04, 03 -> Mês 07, 04 -> Mês 10\n",
    "        pib['Ano'] = pib['Trimestre'].str[:4]\n",
    "        pib['Tri'] = pib['Trimestre'].str[-1].astype(int)\n",
    "        pib['Mes'] = (pib['Tri'] * 3) - 2\n",
    "        pib['Data'] = pd.to_datetime(pib['Ano'] + '-' + pib['Mes'].astype(str) + '-01')\n",
    "        \n",
    "        pib = pib.set_index('Data').sort_index()\n",
    "        \n",
    "        # Filtrar período\n",
    "        pib = pib[(pib.index >= DATA_INICIAL) & (pib.index <= DATA_FINAL)]\n",
    "        \n",
    "        # Rebase para 1999=100 (Média de 1999 = 100)\n",
    "        if not pib.empty:\n",
    "            base_1999 = pib[pib.index.year == 1999]['PIB_Indice'].mean()\n",
    "            pib['PIB_Indice'] = (pib['PIB_Indice'] / base_1999) * 100\n",
    "        \n",
    "        print(f\"Dados PIB coletados: {pib.shape[0]} registros trimestrais.\")\n",
    "        return pib[['PIB_Indice']]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na coleta do PIB: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "df_pib = coleta_pib()\n",
    "df_pib.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b45e06",
   "metadata": {},
   "source": [
    "# 4. Coleta de Expectativas de Inflação (Focus)\n",
    "Coleta das expectativas de mercado para o IPCA anual utilizando o módulo `Expectativas`.\n",
    "O processo envolve:\n",
    "1. Baixar dados do endpoint `ExpectativasMercadoAnuais`.\n",
    "2. Filtrar pelo indicador IPCA.\n",
    "3. Selecionar apenas as expectativas para o **ano corrente** (onde `DataReferencia` é igual ao ano da data de coleta).\n",
    "4. Realizar uma reamostragem mensal calculando a média das expectativas diárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coleta_expectativas():\n",
    "    print(\"Iniciando coleta de Expectativas Focus...\")\n",
    "    em = Expectativas()\n",
    "    ep = em.get_endpoint('ExpectativasMercadoAnuais')\n",
    "    \n",
    "    # Filtra por IPCA e data inicial para otimizar a consulta\n",
    "    try:\n",
    "        df_focus = ep.query().filter(ep.Indicador == 'IPCA').filter(ep.Data >= DATA_INICIAL).collect()\n",
    "        \n",
    "        # Converter Data para datetime\n",
    "        df_focus['Data'] = pd.to_datetime(df_focus['Data'])\n",
    "        df_focus['DataReferencia'] = df_focus['DataReferencia'].astype(int)\n",
    "        \n",
    "        # Filtrar período de análise (garantia adicional)\n",
    "        df_focus = df_focus[(df_focus['Data'] >= DATA_INICIAL) & (df_focus['Data'] <= DATA_FINAL)]\n",
    "        \n",
    "        # Filtrar expectativa para o ano corrente\n",
    "        # Lógica: Queremos saber qual era a expectativa para 2023 em 2023, etc.\n",
    "        df_focus = df_focus[df_focus['DataReferencia'] == df_focus['Data'].dt.year]\n",
    "        \n",
    "        # Selecionar colunas e renomear\n",
    "        df_focus = df_focus[['Data', 'Media']]\n",
    "        df_focus = df_focus.rename(columns={'Media': 'Expectativa_IPCA_AnoCorrente'})\n",
    "        \n",
    "        # Reamostragem mensal (Média mensal das expectativas diárias)\n",
    "        # 'ME' é o alias para Month End no pandas mais recente. Use 'M' se der erro em versões antigas.\n",
    "        df_focus = df_focus.set_index('Data').resample('ME').mean()\n",
    "        \n",
    "        print(f\"Dados Focus processados: {df_focus.shape[0]} registros mensais.\")\n",
    "        return df_focus\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na coleta do Focus: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "df_focus = coleta_expectativas()\n",
    "df_focus.head(), df_focus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d072b02d",
   "metadata": {},
   "source": [
    "# 5. Tratamento e Consolidação\n",
    "Unificação das bases de dados do SGS, PIB e Focus em um único DataFrame com frequência mensal.\n",
    "Realiza-se o alinhamento das datas (início do mês) e tratamento de dados faltantes.\n",
    "Para o PIB (trimestral), os dados serão repetidos ou interpolados para frequência mensal (Forward Fill)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5980c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidar_dados(df_sgs, df_focus, df_pib):\n",
    "    print(\"Consolidando dados...\")\n",
    "    \n",
    "    # Ajuste de índice do Focus para o primeiro dia do mês para alinhar com SGS\n",
    "    df_focus_adj = df_focus.copy()\n",
    "    df_focus_adj.index = df_focus_adj.index.to_period('M').to_timestamp()\n",
    "    \n",
    "    # Merge SGS e Focus\n",
    "    df_final = pd.merge(df_sgs, df_focus_adj, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "    # Merge PIB\n",
    "    # O PIB é trimestral. Ao fazer o merge, teremos NaNs nos meses sem dado.\n",
    "    # Vamos usar forward fill para preencher os meses dentro do trimestre (ou interpolação linear se preferir)\n",
    "    # Aqui usaremos ffill para manter o valor do trimestre até o próximo.\n",
    "    df_final = pd.merge(df_final, df_pib, left_index=True, right_index=True, how='outer')\n",
    "    \n",
    "    # Filtro final de datas para garantir o range solicitado\n",
    "    df_final = df_final[(df_final.index >= DATA_INICIAL) & (df_final.index <= DATA_FINAL)]\n",
    "    \n",
    "    # Preenchimento de dados faltantes\n",
    "    # Primeiro ffill para preencher PIB e eventuais buracos pequenos\n",
    "    df_final = df_final.ffill()\n",
    "    \n",
    "    print(f\"Dataset final consolidado: {df_final.shape}\")\n",
    "    return df_final\n",
    "\n",
    "df_economico = consolidar_dados(df_sgs, df_focus, df_pib)\n",
    "df_economico.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1d750a",
   "metadata": {},
   "source": [
    "# 6. Visualização Exploratória\n",
    "Geração de gráficos para análise visual das séries temporais.\n",
    "- **Gráfico 1**: Comparação entre IPCA acumulado em 12 meses e a Meta Selic.\n",
    "- **Gráfico 2**: Evolução das expectativas de inflação para o ano corrente.\n",
    "- **Gráfico 3**: Evolução do PIB (Índice de Volume)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def plotar_dados(df):\n",
    "    fig, axes = plt.subplots(3, 1, figsize=(14, 15), sharex=True)\n",
    "    \n",
    "    # Gráfico 1: IPCA 12m vs Selic\n",
    "    sns.lineplot(data=df, x=df.index, y='IPCA_12m', ax=axes[0], label='IPCA Acumulado 12m', color='#1f77b4', linewidth=2)\n",
    "    sns.lineplot(data=df, x=df.index, y='Selic_Meta', ax=axes[0], label='Meta Selic', color='#d62728', linestyle='--', linewidth=2)\n",
    "    \n",
    "    axes[0].set_title('Dinâmica da Inflação e Taxa de Juros (1999-2024)', fontsize=16, fontweight='bold')\n",
    "    axes[0].set_ylabel('% a.a.', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gráfico 2: Expectativas\n",
    "    sns.lineplot(data=df, x=df.index, y='Expectativa_IPCA_AnoCorrente', ax=axes[1], label='Focus', color='#2ca02c', linewidth=2)\n",
    "    \n",
    "    axes[1].set_title('Expectativas de Inflação (IPCA ano corrente)', fontsize=16, fontweight='bold')\n",
    "    axes[1].set_ylabel('%', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gráfico 3: PIB\n",
    "    sns.lineplot(data=df, x=df.index, y='PIB_Indice', ax=axes[2], label='PIB (Índice de Volume)', color='#ff7f0e', linewidth=2)\n",
    "    \n",
    "    axes[2].set_title('Evolução do PIB (1999=100)', fontsize=16, fontweight='bold')\n",
    "    axes[2].set_ylabel('Índice (1999=100)', fontsize=12)\n",
    "    axes[2].set_xlabel('Ano', fontsize=10)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Configuração do Eixo X (Anos de 2 em 2)\n",
    "    axes[2].xaxis.set_major_locator(mdates.YearLocator(2))\n",
    "    axes[2].xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Adicionar sombreados para os períodos de choque\n",
    "    periodos_choque = [\n",
    "        ('2002-06-01', '2003-01-01', 'Crise de Confiança\\n(jun/2002-jan/2003)'),\n",
    "        ('2008-09-01', '2009-03-01', 'Crise Financeira Global\\n(set/2008-mar/2009)'),\n",
    "        ('2015-01-01', '2016-12-01', 'Recessão Doméstica\\n(jan/2015-dez/2016)'),\n",
    "        ('2020-03-01', '2020-12-01', 'Pandemia Covid-19\\n(mar/2020-dez/2020)')\n",
    "    ]\n",
    "\n",
    "    # Adicionar sombreado e atualizar legendas\n",
    "    patch_crise = mpatches.Patch(color='gray', alpha=0.2, label='Choques Econômicos')\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        # Adicionar sombreado\n",
    "        for inicio, fim, label in periodos_choque:\n",
    "            start = pd.to_datetime(inicio)\n",
    "            end = pd.to_datetime(fim)\n",
    "            ax.axvspan(start, end, color='gray', alpha=0.2)\n",
    "            \n",
    "            # Adicionar texto apenas no primeiro gráfico (axes[0])\n",
    "            if i == 0:\n",
    "                mid_point = start + (end - start) / 2\n",
    "                # Posicionar texto no topo da área do gráfico\n",
    "                ax.text(mid_point, 0.68, label, transform=ax.get_xaxis_transform(),\n",
    "                        ha='center', va='top', fontsize=12, color='black',\n",
    "                        bbox=dict(facecolor='white', alpha=0.6, edgecolor='none', pad=2))\n",
    "        \n",
    "        # Atualizar legenda\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        \n",
    "        if i == 3:\n",
    "            loc = 'upper right'\n",
    "        elif i == 1:\n",
    "            loc = 'upper right'\n",
    "        elif i == 2:\n",
    "            loc = 'lower right'\n",
    "        else:\n",
    "            loc = 'upper right'\n",
    "            \n",
    "        ax.legend(handles=handles + [patch_crise], loc=loc, frameon=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plotar_dados(df_economico)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af306fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar o gráfico para paper/graficos/series_macroeconomicas.png\n",
    "# fig.savefig('/home/fernando/Documentos/dev/brazil-taylor-determinacy/paper/graficos/series_macroeconomicas.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57863c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_economico.describe().to_latex('/home/fernando/Documentos/dev/brazil-taylor-determinacy/paper/tabelas/estatisticas_descritivas.tex', float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar dados para CSV\n",
    "df_economico.to_csv('/home/fernando/Documentos/dev/brazil-taylor-determinacy/dados/fernando/dados_economicos_consolidados.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artmacro2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
